diff --git a/include/media/mediarecorder.h b/include/media/mediarecorder.h
index bd29d74..a4c935f 100755
--- a/include/media/mediarecorder.h
+++ b/include/media/mediarecorder.h
@@ -40,7 +40,7 @@ typedef void (*media_completion_f)(status_t status, void *cookie);
 enum video_source {
     VIDEO_SOURCE_DEFAULT = 0,
     VIDEO_SOURCE_CAMERA = 1,
-    VIDEO_SOURCE_SURFACE = 2,
+    VIDEO_SOURCE_GRALLOC_BUFFER = 2,
 
     VIDEO_SOURCE_LIST_END  // must be last - used to validate audio source type
 };
diff --git a/media/libmediaplayerservice/MediaRecorderClient.cpp b/media/libmediaplayerservice/MediaRecorderClient.cpp
index 8c34a47..de52bdd 100644
--- a/media/libmediaplayerservice/MediaRecorderClient.cpp
+++ b/media/libmediaplayerservice/MediaRecorderClient.cpp
@@ -95,8 +95,8 @@ status_t MediaRecorderClient::setPreviewSurface(const sp<IGraphicBufferProducer>
 status_t MediaRecorderClient::setVideoSource(int vs)
 {
     ALOGV("setVideoSource(%d)", vs);
-    // Check camera permission for sources other than SURFACE
-    if (vs != VIDEO_SOURCE_SURFACE && !checkPermission(cameraPermission)) {
+    // Check camera permission
+    if (!checkPermission(cameraPermission)) {
         return PERMISSION_DENIED;
     }
     Mutex::Autolock lock(mLock);
diff --git a/media/libmediaplayerservice/StagefrightRecorder.cpp b/media/libmediaplayerservice/StagefrightRecorder.cpp
index 90d4a25..b715699 100644
--- a/media/libmediaplayerservice/StagefrightRecorder.cpp
+++ b/media/libmediaplayerservice/StagefrightRecorder.cpp
@@ -42,12 +42,14 @@
 #include <media/stagefright/MediaDefs.h>
 #include <media/stagefright/MetaData.h>
 #include <media/stagefright/MediaCodecSource.h>
+#include <media/stagefright/SurfaceMediaSource.h>
 #include <media/stagefright/OMXClient.h>
 #include <media/stagefright/OMXCodec.h>
 #include <media/stagefright/WAVEWriter.h>
 #include <media/MediaProfiles.h>
 #include <camera/ICamera.h>
 #include <camera/CameraParameters.h>
+#include <gui/Surface.h>
 
 #include <utils/Errors.h>
 #include <sys/types.h>
@@ -90,7 +92,8 @@ StagefrightRecorder::StagefrightRecorder()
       mVideoSource(VIDEO_SOURCE_LIST_END),
       mCaptureTimeLapse(false),
       mStarted(false),
-      mRecPaused(false) {
+      mRecPaused(false),
+      mSurfaceMediaSource(NULL) {
 
     ALOGV("Constructor");
     reset();
@@ -123,7 +126,7 @@ status_t StagefrightRecorder::init() {
 // while encoding GL Frames
 sp<IGraphicBufferProducer> StagefrightRecorder::querySurfaceMediaSource() const {
     ALOGV("Get SurfaceMediaSource");
-    return mGraphicBufferProducer;
+    return mSurfaceMediaSource->getProducer();
 }
 
 status_t StagefrightRecorder::setAudioSource(audio_source_t as) {
@@ -868,9 +871,6 @@ status_t StagefrightRecorder::prepareInternal() {
 }
 
 status_t StagefrightRecorder::prepare() {
-    if (mVideoSource == VIDEO_SOURCE_SURFACE) {
-        return prepareInternal();
-    }
     return OK;
 }
 
@@ -903,11 +903,9 @@ status_t StagefrightRecorder::start() {
     }
     status_t status = OK;
 
-    if (mVideoSource != VIDEO_SOURCE_SURFACE) {
-        status = prepareInternal();
-        if (status != OK) {
-            return status;
-        }
+    status = prepareInternal();
+    if (status != OK) {
+        return status;
     }
 
     if (mAudioSource != AUDIO_SOURCE_CNT) {
@@ -1554,14 +1552,49 @@ status_t StagefrightRecorder::setupMediaSource(
             return err;
         }
         *mediaSource = cameraSource;
-    } else if (mVideoSource == VIDEO_SOURCE_SURFACE) {
-        *mediaSource = NULL;
+    } else if (mVideoSource == VIDEO_SOURCE_GRALLOC_BUFFER) {
+        // If using GRAlloc buffers, setup surfacemediasource.
+        // Later a handle to that will be passed
+        // to the client side when queried
+        status_t err = setupSurfaceMediaSource();
+        if (err != OK) {
+            return err;
+        }
+        *mediaSource = mSurfaceMediaSource;
     } else {
         return INVALID_OPERATION;
     }
     return OK;
 }
 
+// setupSurfaceMediaSource creates a source with the given
+// width and height and framerate.
+// TODO: This could go in a static function inside SurfaceMediaSource
+// similar to that in CameraSource
+status_t StagefrightRecorder::setupSurfaceMediaSource() {
+    status_t err = OK;
+    mSurfaceMediaSource = new SurfaceMediaSource(mVideoWidth, mVideoHeight);
+    if (mSurfaceMediaSource == NULL) {
+        return NO_INIT;
+    }
+
+    if (mFrameRate == -1) {
+        int32_t frameRate = 0;
+        CHECK (mSurfaceMediaSource->getFormat()->findInt32(
+                                        kKeyFrameRate, &frameRate));
+        ALOGI("Frame rate is not explicitly set. Use the current frame "
+             "rate (%d fps)", frameRate);
+        mFrameRate = frameRate;
+    } else {
+        err = mSurfaceMediaSource->setFrameRate(mFrameRate);
+    }
+    CHECK(mFrameRate != -1);
+
+    mIsMetaDataStoredInVideoBuffers =
+        mSurfaceMediaSource->isMetaDataStoredInVideoBuffers();
+    return err;
+}
+
 status_t StagefrightRecorder::setupCameraSource(
         sp<CameraSource> *cameraSource) {
     ExtendedStats::AutoProfile autoProfile(
@@ -1634,27 +1667,29 @@ status_t StagefrightRecorder::setupVideoEncoder(
 
     source->clear();
 
-    sp<AMessage> format = new AMessage();
+    sp<MetaData> enc_meta = new MetaData;
+    enc_meta->setInt32(kKeyBitRate, mVideoBitRate);
+    enc_meta->setInt32(kKeyFrameRate, mFrameRate);
 
     switch (mVideoEncoder) {
         case VIDEO_ENCODER_H263:
-            format->setString("mime", MEDIA_MIMETYPE_VIDEO_H263);
+            enc_meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_VIDEO_H263);
             break;
 
         case VIDEO_ENCODER_MPEG_4_SP:
-            format->setString("mime", MEDIA_MIMETYPE_VIDEO_MPEG4);
+            enc_meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_VIDEO_MPEG4);
             break;
 
         case VIDEO_ENCODER_H264:
-            format->setString("mime", MEDIA_MIMETYPE_VIDEO_AVC);
+            enc_meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_VIDEO_AVC);
             break;
 
         case VIDEO_ENCODER_VP8:
-            format->setString("mime", MEDIA_MIMETYPE_VIDEO_VP8);
+            enc_meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_VIDEO_VP8);
             break;
 
         case VIDEO_ENCODER_H265:
-            format->setString("mime", MEDIA_MIMETYPE_VIDEO_HEVC);
+            enc_meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_VIDEO_HEVC);
             break;
 
         default:
@@ -1672,71 +1707,55 @@ status_t StagefrightRecorder::setupVideoEncoder(
         CHECK(meta->findInt32(kKeySliceHeight, &sliceHeight));
         CHECK(meta->findInt32(kKeyColorFormat, &colorFormat));
 
-        format->setInt32("width", width);
-        format->setInt32("height", height);
-        format->setInt32("stride", stride);
-        format->setInt32("slice-height", sliceHeight);
-        format->setInt32("color-format", colorFormat);
+        enc_meta->setInt32(kKeyWidth, width);
+        enc_meta->setInt32(kKeyHeight, height);
+        enc_meta->setInt32(kKeyIFramesInterval, mIFramesIntervalSec);
+        enc_meta->setInt32(kKeyStride, stride);
+        enc_meta->setInt32(kKeySliceHeight, sliceHeight);
+        enc_meta->setInt32(kKeyColorFormat, colorFormat);
     } else {
-        format->setInt32("width", mVideoWidth);
-        format->setInt32("height", mVideoHeight);
-        format->setInt32("stride", mVideoWidth);
-        format->setInt32("slice-height", mVideoWidth);
-        format->setInt32("color-format", OMX_COLOR_FormatAndroidOpaque);
-
-        // set up time lapse/slow motion for surface source
-        if (mCaptureTimeLapse) {
-            if (mTimeBetweenTimeLapseFrameCaptureUs <= 0) {
-                ALOGE("Invalid mTimeBetweenTimeLapseFrameCaptureUs value: %lld",
-                    mTimeBetweenTimeLapseFrameCaptureUs);
-                return BAD_VALUE;
-            }
-            format->setInt64("time-lapse",
-                    mTimeBetweenTimeLapseFrameCaptureUs);
-        }
+        enc_meta->setInt32(kKeyWidth, mVideoWidth);
+        enc_meta->setInt32(kKeyHeight, mVideoHeight);
+        enc_meta->setInt32(kKeyIFramesInterval, mIFramesIntervalSec);
+        enc_meta->setInt32(kKeyStride, mVideoWidth);
+        enc_meta->setInt32(kKeySliceHeight, mVideoHeight);
+        enc_meta->setInt32(kKeyColorFormat, OMX_COLOR_FormatAndroidOpaque);
     }
 
-    format->setInt32("bitrate", mVideoBitRate);
-    format->setInt32("frame-rate", mFrameRate);
-    format->setInt32("i-frame-interval", mIFramesIntervalSec);
+    enc_meta->setInt32(kKeyBitRate, mVideoBitRate);
+    enc_meta->setInt32(kKeyFrameRate, mFrameRate);
+    enc_meta->setInt32(kKeyIFramesInterval, mIFramesIntervalSec);
 
     if (mVideoTimeScale > 0) {
-        format->setInt32("time-scale", mVideoTimeScale);
-    }
-
-    if (cameraSource != NULL) {
-        sp<MetaData> meta = cameraSource->getFormat();
-        status_t retVal = ExtendedUtils::HFR::initializeHFR(
-                meta, format, mMaxFileDurationUs, mVideoEncoder);
-        if (retVal != OK) {
-            return retVal;
-        }
+        enc_meta->setInt32(kKeyTimeScale, mVideoTimeScale);
     }
 
     ExtendedUtils::ShellProp::setEncoderProfile(mVideoEncoder,
             mVideoEncoderProfile, mVideoEncoderLevel);
 
     if (mVideoEncoderProfile != -1) {
-        format->setInt32("profile", mVideoEncoderProfile);
+        enc_meta->setInt32(kKeyVideoProfile, mVideoEncoderProfile);
     }
     if (mVideoEncoderLevel != -1) {
-        format->setInt32("level", mVideoEncoderLevel);
+        enc_meta->setInt32(kKeyVideoLevel, mVideoEncoderLevel);
     }
 
-    uint32_t flags = 0;
+    OMXClient client;
+    CHECK_EQ(client.connect(), (status_t)OK);
+
+    uint32_t encoder_flags = 0;
     if (mIsMetaDataStoredInVideoBuffers) {
-        flags |= MediaCodecSource::FLAG_USE_METADATA_INPUT;
+        encoder_flags |= OMXCodec::kStoreMetaDataInVideoBuffers;
     }
 
-    if (cameraSource == NULL) {
-        flags |= MediaCodecSource::FLAG_USE_SURFACE_INPUT;
+    if (mCaptureTimeLapse) {
+        encoder_flags |= OMXCodec::kOnlySubmitOneInputBufferAtOneTime;
     }
 
-    if (mRecorderExtendedStats != NULL) {
-        format->setObject(MEDIA_EXTENDED_STATS, mRecorderExtendedStats);
-    }
-    sp<MediaCodecSource> encoder =
-            MediaCodecSource::Create(mLooper, format, cameraSource, flags);
+    sp<MediaSource> encoder = OMXCodec::Create(
+            client.interface(), enc_meta,
+            true /* createEncoder */, cameraSource,
+            NULL, encoder_flags);
     if (encoder == NULL) {
         ALOGE("Failed to create video encoder");
         // When the encoder fails to be created, we need
@@ -1748,12 +1767,6 @@ status_t StagefrightRecorder::setupVideoEncoder(
         return UNKNOWN_ERROR;
     }
 
-    if (cameraSource == NULL) {
-        mGraphicBufferProducer = encoder->getGraphicBufferProducer();
-    }
-
-    mVideoSourceNode = cameraSource;
-    mVideoEncoderOMX = encoder;
     *source = encoder;
 
     return OK;
@@ -1851,13 +1864,8 @@ status_t StagefrightRecorder::setupMPEG4orWEBMRecording() {
     if (mMaxFileSizeBytes != 0) {
         writer->setMaxFileSize(mMaxFileSizeBytes);
     }
-    if (mVideoSource == VIDEO_SOURCE_DEFAULT
-            || mVideoSource == VIDEO_SOURCE_CAMERA) {
-        mStartTimeOffsetMs = mEncoderProfiles->getStartTimeOffsetMs(mCameraId);
-    } else if (mVideoSource == VIDEO_SOURCE_SURFACE) {
-        // surface source doesn't need large initial delay
-        mStartTimeOffsetMs = 200;
-    }
+
+    mStartTimeOffsetMs = mEncoderProfiles->getStartTimeOffsetMs(mCameraId);
     if (mStartTimeOffsetMs > 0) {
         writer->setStartTimeOffsetMs(mStartTimeOffsetMs);
     }
@@ -1953,8 +1961,6 @@ status_t StagefrightRecorder::stop() {
         mWriter.clear();
     }
 
-    mGraphicBufferProducer.clear();
-
     if (mOutputFd >= 0) {
         ::close(mOutputFd);
         mOutputFd = -1;
diff --git a/media/libmediaplayerservice/StagefrightRecorder.h b/media/libmediaplayerservice/StagefrightRecorder.h
index 527b645..e446caa 100644
--- a/media/libmediaplayerservice/StagefrightRecorder.h
+++ b/media/libmediaplayerservice/StagefrightRecorder.h
@@ -141,6 +141,7 @@ private:
     // will be sent to the client side using which the
     // frame buffers will be queued and dequeued
     sp<IGraphicBufferProducer> mGraphicBufferProducer;
+    sp<SurfaceMediaSource> mSurfaceMediaSource;
     sp<ALooper> mLooper;
 
     sp<RecorderExtendedStats> mRecorderExtendedStats;
@@ -162,6 +163,9 @@ private:
     // depending on the videosource type
     status_t setupMediaSource(sp<MediaSource> *mediaSource);
     status_t setupCameraSource(sp<CameraSource> *cameraSource);
+    // setup the surfacemediasource for the encoder
+    status_t setupSurfaceMediaSource();
+
     status_t setupAudioEncoder(const sp<MediaWriter>& writer);
     status_t setupVideoEncoder(sp<MediaSource> cameraSource, sp<MediaSource> *source);
 
diff --git a/media/libstagefright/MPEG4Writer.cpp b/media/libstagefright/MPEG4Writer.cpp
index b94e334..13d5992 100644
--- a/media/libstagefright/MPEG4Writer.cpp
+++ b/media/libstagefright/MPEG4Writer.cpp
@@ -1839,7 +1839,7 @@ status_t MPEG4Writer::Track::pause() {
 }
 
 status_t MPEG4Writer::Track::stop() {
-    ALOGD("%s track stopping", mIsAudio? "Audio": "Video");
+    ALOGD("Stopping %s track", mIsAudio? "Audio": "Video");
     if (!mStarted) {
         ALOGE("Stop() called but track is not started");
         return ERROR_END_OF_STREAM;
@@ -1850,18 +1850,19 @@ status_t MPEG4Writer::Track::stop() {
     }
     mDone = true;
 
-    ALOGD("%s track source stopping", mIsAudio? "Audio": "Video");
-    mSource->stop();
-    ALOGD("%s track source stopped", mIsAudio? "Audio": "Video");
-
     void *dummy;
     pthread_join(mThread, &dummy);
     status_t err = static_cast<status_t>(reinterpret_cast<uintptr_t>(dummy));
 
-    if (mOwner->exceedsFileSizeLimit() && mStszTableEntries->count() == 0) {
-        ALOGE(" Filesize limit exceeded and zero samples written ");
-        return ERROR_END_OF_STREAM;
+    ALOGD("Stopping %s track source", mIsAudio? "Audio": "Video");
+    {
+        status_t status = mSource->stop();
+        if (err == OK && status != OK && status != ERROR_END_OF_STREAM) {
+            err = status;
+        }
     }
+
+    ALOGD("%s track stopped", mIsAudio? "Audio": "Video");
     return err;
 }
 
diff --git a/media/libstagefright/tests/SurfaceMediaSource_test.cpp b/media/libstagefright/tests/SurfaceMediaSource_test.cpp
index fd889f9..6778a47 100644
--- a/media/libstagefright/tests/SurfaceMediaSource_test.cpp
+++ b/media/libstagefright/tests/SurfaceMediaSource_test.cpp
@@ -744,8 +744,9 @@ TEST_F(SurfaceMediaSourceTest, DISABLED_EncodingFromCpuYV12BufferNpotWriteMediaS
     CHECK(fd >= 0);
 
     sp<MediaRecorder> mr = SurfaceMediaSourceGLTest::setUpMediaRecorder(fd,
-            VIDEO_SOURCE_SURFACE, OUTPUT_FORMAT_MPEG_4, VIDEO_ENCODER_H264,
-            mYuvTexWidth, mYuvTexHeight, 30);
+            VIDEO_SOURCE_GRALLOC_BUFFER,
+            OUTPUT_FORMAT_MPEG_4, VIDEO_ENCODER_H264, mYuvTexWidth,
+            mYuvTexHeight, 30);
     // get the reference to the surfacemediasource living in
     // mediaserver that is created by stagefrightrecorder
     sp<IGraphicBufferProducer> iST = mr->querySurfaceMediaSourceFromMediaServer();
@@ -877,7 +878,7 @@ TEST_F(SurfaceMediaSourceGLTest, EncodingFromGLRgbaSameImageEachBufNpotWrite) {
     }
     CHECK(fd >= 0);
 
-    sp<MediaRecorder> mr = setUpMediaRecorder(fd, VIDEO_SOURCE_SURFACE,
+    sp<MediaRecorder> mr = setUpMediaRecorder(fd, VIDEO_SOURCE_GRALLOC_BUFFER,
             OUTPUT_FORMAT_MPEG_4, VIDEO_ENCODER_H264, mYuvTexWidth, mYuvTexHeight, 30);
 
     // get the reference to the surfacemediasource living in
@@ -920,7 +921,7 @@ TEST_F(SurfaceMediaSourceGLTest, EncodingFromGLRgbaDiffImageEachBufNpotWrite) {
     }
     CHECK(fd >= 0);
 
-    sp<MediaRecorder> mr = setUpMediaRecorder(fd, VIDEO_SOURCE_SURFACE,
+    sp<MediaRecorder> mr = setUpMediaRecorder(fd, VIDEO_SOURCE_GRALLOC_BUFFER,
             OUTPUT_FORMAT_MPEG_4, VIDEO_ENCODER_H264, mYuvTexWidth, mYuvTexHeight, 30);
 
     // get the reference to the surfacemediasource living in
-- 
2.5.0

